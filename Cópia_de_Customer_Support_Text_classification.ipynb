{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 5537432,
          "sourceType": "datasetVersion",
          "datasetId": 3191511
        }
      ],
      "dockerImageVersionId": 30822,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "scodepy_customer_support_intent_dataset_path = kagglehub.dataset_download('scodepy/customer-support-intent-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Sz1WX4o7RurC",
        "outputId": "dc9c0ced-1846-43ce-d377-e769af90eac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a567472",
        "outputId": "656fd9d7-4baa-42e3-fb83-cd9484174ba5"
      },
      "source": [
        "%pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"scodepy/customer-support-intent-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-06T08:04:38.325916Z",
          "iopub.execute_input": "2025-01-06T08:04:38.326269Z",
          "iopub.status.idle": "2025-01-06T08:04:39.184063Z",
          "shell.execute_reply.started": "2025-01-06T08:04:38.326209Z",
          "shell.execute_reply": "2025-01-06T08:04:39.182881Z"
        },
        "id": "1t7O-BnyRurE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e6e3f4-20e9-48a7-c88a-f52ffeb1172b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/customer-support-intent-dataset\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gensim.downloader as api\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Bidirectional, Dropout, GlobalMaxPool1D, BatchNormalization\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-06T08:04:42.438343Z",
          "iopub.execute_input": "2025-01-06T08:04:42.438961Z",
          "iopub.status.idle": "2025-01-06T08:05:17.12035Z",
          "shell.execute_reply.started": "2025-01-06T08:04:42.43891Z",
          "shell.execute_reply": "2025-01-06T08:05:17.119333Z"
        },
        "id": "_ILf6VUaRurE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/Bitext_Sample_Customer_Service_Training_Dataset.csv\")\n",
        "validation = pd.read_csv(\"/content/Bitext_Sample_Customer_Service_Validation_Dataset.csv\")\n",
        "test = pd.read_csv(\"/content/Bitext_Sample_Customer_Service_Testing_Dataset.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-06T08:06:00.50696Z",
          "iopub.execute_input": "2025-01-06T08:06:00.507712Z",
          "iopub.status.idle": "2025-01-06T08:06:00.559773Z",
          "shell.execute_reply.started": "2025-01-06T08:06:00.507675Z",
          "shell.execute_reply": "2025-01-06T08:06:00.558608Z"
        },
        "id": "VVNPeWRKRurF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the DataFrames into a list\n",
        "data_frames = [train, test, validation]\n",
        "\n",
        "# Perform Label Encoding for each DataFrame in the list\n",
        "le = LabelEncoder()\n",
        "for df in data_frames:\n",
        "    le.fit(df['intent'])\n",
        "    df['intent'] = le.transform(df['intent'])\n",
        "\n",
        "# Splitting to features and target\n",
        "X_train, X_test , X_validation = train['utterance'] , test['utterance'], validation['utterance']\n",
        "y_train, y_test , y_validation = train['intent'], test['intent'], validation['intent']\n",
        "# Convert the text data into sequences of integer values\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_validation_sequences = tokenizer.texts_to_sequences(X_validation)\n",
        "\n",
        "# Pad the sequences to ensure they all have the same length\n",
        "maxlen = 100\n",
        "X_train_padded = pad_sequences(X_train_sequences, padding='post', truncating='post', maxlen=maxlen)\n",
        "X_validation_padded = pad_sequences(X_validation_sequences, padding='post', truncating='post', maxlen=maxlen)\n",
        "\n",
        "# Load the pre-trained GloVe embeddings\n",
        "word_vectors = api.load('glove-wiki-gigaword-100')\n",
        "\n",
        "# Create the embedding layer\n",
        "embedding_dim = 100\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word_vectors:\n",
        "        embedding_vector = word_vectors[word]\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-06T08:06:03.821907Z",
          "iopub.execute_input": "2025-01-06T08:06:03.822278Z",
          "iopub.status.idle": "2025-01-06T08:06:53.552236Z",
          "shell.execute_reply.started": "2025-01-06T08:06:03.822247Z",
          "shell.execute_reply": "2025-01-06T08:06:53.550986Z"
        },
        "id": "OrhGib97RurF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4033850d-91ea-4046-ca2b-cc995acc05f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = train['intent'].nunique()\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "\n",
        "model.add(Bidirectional(LSTM(\n",
        "        100,\n",
        "        return_sequences = True,\n",
        "        recurrent_dropout=0.2)))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation = \"relu\"))\n",
        "model.add(Dense(64, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dense(512, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation = 'softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_padded, y_train, epochs=10, batch_size=64, validation_data=(X_validation_padded, y_validation))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-06T08:08:02.653453Z",
          "iopub.execute_input": "2025-01-06T08:08:02.653879Z",
          "iopub.status.idle": "2025-01-06T08:10:42.889217Z",
          "shell.execute_reply.started": "2025-01-06T08:08:02.653828Z",
          "shell.execute_reply": "2025-01-06T08:10:42.888189Z"
        },
        "id": "g-0asuxpRurG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "013a540d-c7f3-4c68-fd16-4a205927c9ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 476ms/step - accuracy: 0.0528 - loss: 3.3129 - val_accuracy: 0.2665 - val_loss: 3.1870\n",
            "Epoch 2/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 447ms/step - accuracy: 0.2509 - loss: 2.3986 - val_accuracy: 0.5355 - val_loss: 2.1454\n",
            "Epoch 3/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 463ms/step - accuracy: 0.5217 - loss: 1.3626 - val_accuracy: 0.8325 - val_loss: 1.0670\n",
            "Epoch 4/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 448ms/step - accuracy: 0.6552 - loss: 0.9531 - val_accuracy: 0.8900 - val_loss: 0.4281\n",
            "Epoch 5/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 460ms/step - accuracy: 0.7294 - loss: 0.7553 - val_accuracy: 0.9022 - val_loss: 0.2309\n",
            "Epoch 6/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 453ms/step - accuracy: 0.7652 - loss: 0.6341 - val_accuracy: 0.9633 - val_loss: 0.1520\n",
            "Epoch 7/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 463ms/step - accuracy: 0.8092 - loss: 0.5361 - val_accuracy: 0.9511 - val_loss: 0.1254\n",
            "Epoch 8/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 464ms/step - accuracy: 0.8393 - loss: 0.4577 - val_accuracy: 0.9731 - val_loss: 0.1012\n",
            "Epoch 9/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 455ms/step - accuracy: 0.8545 - loss: 0.4174 - val_accuracy: 0.9670 - val_loss: 0.1038\n",
            "Epoch 10/10\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 466ms/step - accuracy: 0.8760 - loss: 0.3590 - val_accuracy: 0.9841 - val_loss: 0.0824\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e703d3e2610>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_padded = pad_sequences(X_test_sequences, padding='post', truncating='post', maxlen=maxlen)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-06T08:10:48.299117Z",
          "iopub.execute_input": "2025-01-06T08:10:48.299501Z",
          "iopub.status.idle": "2025-01-06T08:10:48.318094Z",
          "shell.execute_reply.started": "2025-01-06T08:10:48.299469Z",
          "shell.execute_reply": "2025-01-06T08:10:48.3167Z"
        },
        "id": "RJ2eyc6IRurG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation on the test set\n",
        "model.evaluate(X_test_padded,y_test)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-06T08:10:54.186696Z",
          "iopub.execute_input": "2025-01-06T08:10:54.187102Z",
          "iopub.status.idle": "2025-01-06T08:10:55.030827Z",
          "shell.execute_reply.started": "2025-01-06T08:10:54.187069Z",
          "shell.execute_reply": "2025-01-06T08:10:55.029979Z"
        },
        "id": "L2Wj7iaGRurH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7007699-7a97-4631-8057-0add98fe4a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.9849 - loss: 0.0838\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08710349351167679, 0.9865525960922241]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in HDF5 format\n",
        "model.save('/kaggle/working/intent_model.h5')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-06T08:11:03.248396Z",
          "iopub.execute_input": "2025-01-06T08:11:03.248751Z",
          "iopub.status.idle": "2025-01-06T08:11:03.338082Z",
          "shell.execute_reply.started": "2025-01-06T08:11:03.248722Z",
          "shell.execute_reply": "2025-01-06T08:11:03.33657Z"
        },
        "id": "UqsTOnYlRurI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f8e294a-4f28-4ace-d2c7-04e6b82c23fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all unique encoded categories from the training data\n",
        "encoded_categories = train['intent'].unique()\n",
        "\n",
        "# Use the LabelEncoder's inverse_transform to map numbers back to original categories\n",
        "decoded_categories = le.inverse_transform(encoded_categories)\n",
        "\n",
        "# Print the mapping\n",
        "mapping = dict(zip(encoded_categories, decoded_categories))\n",
        "print(\"Number-to-Category Mapping:\")\n",
        "for number, category in mapping.items():\n",
        "    print(f\"{number} -> {category}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-06T08:11:06.240707Z",
          "iopub.execute_input": "2025-01-06T08:11:06.241324Z",
          "iopub.status.idle": "2025-01-06T08:11:06.252659Z",
          "shell.execute_reply.started": "2025-01-06T08:11:06.241282Z",
          "shell.execute_reply": "2025-01-06T08:11:06.251485Z"
        },
        "id": "Y96rUTwBRurI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1858f1a-be27-410c-ceef-09051346b07e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number-to-Category Mapping:\n",
            "0 -> cancel_order\n",
            "1 -> change_order\n",
            "2 -> change_shipping_address\n",
            "3 -> check_cancellation_fee\n",
            "4 -> check_invoice\n",
            "5 -> check_payment_methods\n",
            "6 -> check_refund_policy\n",
            "7 -> complaint\n",
            "8 -> contact_customer_service\n",
            "9 -> contact_human_agent\n",
            "10 -> create_account\n",
            "11 -> delete_account\n",
            "12 -> delivery_options\n",
            "13 -> delivery_period\n",
            "14 -> edit_account\n",
            "15 -> get_invoice\n",
            "16 -> get_refund\n",
            "17 -> newsletter_subscription\n",
            "18 -> payment_issue\n",
            "19 -> place_order\n",
            "20 -> recover_password\n",
            "21 -> registration_problems\n",
            "22 -> review\n",
            "23 -> set_up_shipping_address\n",
            "24 -> switch_account\n",
            "25 -> track_order\n",
            "26 -> track_refund\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/kaggle/working/intent_model.h5')\n",
        "\n",
        "# Example single query\n",
        "single_query = \"I'm having trouble with my electric bill\"\n",
        "\n",
        "# Tokenize the query\n",
        "single_query_sequence = tokenizer.texts_to_sequences([single_query])  # Wrap in a list to maintain 2D input\n",
        "\n",
        "# Pad the sequence\n",
        "single_query_padded = pad_sequences(single_query_sequence, padding='post', truncating='post', maxlen=maxlen)\n",
        "\n",
        "# Get prediction\n",
        "prediction = model.predict(single_query_padded)\n",
        "\n",
        "# Get the predicted class (numeric)\n",
        "predicted_class = prediction.argmax(axis=-1)[0]\n",
        "\n",
        "# Convert numeric class back to original category label\n",
        "predicted_label = le.inverse_transform([predicted_class])[0]\n",
        "\n",
        "print(\"Intenção identificada:\", predicted_label)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-06T08:14:17.864753Z",
          "iopub.execute_input": "2025-01-06T08:14:17.865228Z",
          "iopub.status.idle": "2025-01-06T08:14:18.546095Z",
          "shell.execute_reply.started": "2025-01-06T08:14:17.865191Z",
          "shell.execute_reply": "2025-01-06T08:14:18.544813Z"
        },
        "id": "BQ1eb4uyRurI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "494c71e4-5efa-4ac9-b144-5b5f299bba95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Intenção identificada: payment_issue\n"
          ]
        }
      ],
      "execution_count": 14
    }
  ]
}